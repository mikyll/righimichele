<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<!-- saved from url=(0128)https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.issLabStart/userDocs/template2021.html -->
<html><!--
<link rel="stylesheet" type="text/css" href="../css/issStyle1.css">
<script type="text/htmlpreview" src="../css/issStyle.js"></script>
--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">
body
{
    margin-left:  30px;
    margin-right: 30px;
};

P
{
    font-family: Tahoma;
    font-size: 10pt;
};

a, a:visited, a:active, a:link, a:hover {
    text-decoration: underline;
    color: #545454;
    background-color: transparent;
	font-size: 93%;
}

a:hover {
    background-color: #cccccc;
}


hr {
    clear: both;
    height: 1px;
    color: #242424;
    background-color: transparent;
}

h1, h2, h3 {
    color: #242424;
    clear: left;
    font: 100% Tahoma, Helvetica, Arial, sans-serif;
    margin-bottom: 0.5em;
    padding-top: 0.5em;
	border-radius: 10px;
	padding: 5px;
}

top {
	width: 100%;
}


#i {
    color: #ff1010;
}
tt{
	font-family: "Arial";
    font-size: 90%;
	color: #006600;
}
em{
	font-family: "Arial";
    font-size: 80%;
	font-weight: bold;
	border-style:solid;
	border-color: #abe876;
    color: #1632cc;
}
bc{
	font-family: "Arial";
	font-size: 90%;
	font-weight: bold;
    color: #990000;
	background-color: #fcf8c7;
}
ks{
	font-family: "Arial";
	font-weight: bold;
    color: #0000CD	;
	font-size: 90%;
}
kc{
	font-family: "Arial";
	font-weight: bold;
    color: #008000	;
	font-size: 90%;
}
pre{
	font-family: "Consolas";
	font-size: 85%;
	background-color: #f5f5f5;
	border: 1.5px solid silver;
	padding: 5px;
}
m{
	font-family: "Helvetica";
	line-height: 100%;
 	font-size: 75%;
}
div.body{
	 
    font-size: 18px;
}
k{
    color: #990000;
	font-weight: bold;
	font-size: 90%;
}
h1 {
    font-size: 150%;
    background-color: #b2c0ff;
	padding: 10px;
}

h2 {
    background-color: #9ed8ff;
    font-size: 130%;
}

h3 {
	background-color: #e6ccff;
    font-size: 100%;
}
h4 {
    background-color: #ccffcc;
    font-size: 100%;
	width: 95%;
	border-radius: 5px;
	padding: 2px;
}
h5 {
    background-color: #d5ffb0;
    font-size: 100%;

}
div.req{
	background-color: #d9ffb3;
    font-size: 18px;
	width: 700px;
    border: 3px solid green;
    padding: 15px;
    margin: 10px;
}
div.remark{
	background-color: #E3F2FD;
    border: 1.5px solid #d5f2ed;
    padding: 15px;
    margin: 10px;
	border-radius: 25px;
}
table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}

ol, ul, li {
  margin: 0;
  margin-left: 10px;
  padding: 0;
  padding-bottom: 5px;
}

table, th, td {
	border: 1px solid black;
}

img {
	border: 1.5px solid #d5f2ed

}

a, a:visited, a:active, a:link, a:hover {
    text-decoration: underline;
    color: #545454;
    background-color: transparent;
}

div.wrapdesc{
	width: 90%;
	margin: auto;
}

div.imagedesc{
	width: 85%;
	margin: auto;
}
span.mark {
	background-color: yellow;
	color: black;
}
span#pensiero {
	background-color: white;
}
div.code {
	padding: 10px;
	border: 1px solid silver;
	background-color: whitesmoke;
	font-family: monospace;
	font-size: 14px;
}
span.command {
	color: green;
	font-weight: 900;
}
a#github {
	color: white;
}
a#github:visited {
	color: white;
}
a#github:hover {
	color: white;
	background-color: black;
}
div#footer:hover {

}

</style>
    
<!--<base href="https://raw.githubusercontent.com/anatali/issLab2021/master/it.unibo.issLabStart/userDocs/template2021.html">--><base href=".">
   
<title>Michele Righi CE 2021</title></head>
    
<body>
<div id="top">
	<h1>Lab ISS | the project cautiousExplorer<font size="5"></font> </h1>
</div>  

<div class="body"> 
<!-- ========================================================================= -->
	<h2>Introduction</h2>
	<div class="remark">
		This case-study starts to deal with the design and development of 
		proactive/reactive software systems that use aynchronous exchange of 
		information.
	</div>
	
<!-- ------------------------------------------------------------------------- -->
	<h2>Requirements</h2>
	<div class="remark">
		Design and build a software system that allow the robot described in 
		<a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.virtualRobot2020/userDocs/VirtualRobot2021.html" target="lab">
			<em>VirtualRobot2021.html</em>
		</a>
		to exibit the following behaviour:
		<ul>
			<li>the robot lives in a closed environment, delimited by walls that includes one or more devices (e.g. sonar) able to detect its presence;</li>
			<li>the robot has a <ks>den</ks> for refuge, located near a wall;</li>
			<li>the robot works as an <i>explorer of the environment</i>. Starting from its <ks>den</ks>,  the robot moves
			(either randomly or - preferably - in a more organized way) with the aim to find the fixed obstacles around the <ks>den</ks>. 
			The presence of mobile obstacles is (at the moment) excluded;</li>
			<li>since the robot is <i>'cautious'</i>,  it  returns immediately to the <ks>den</ks> as soon as it finds an obstacle.
			Optionally, it should also return to the <ks>den</ks> when a sonar detects its presence;</li>
			<li>the robot should remember the position of the obstacles found, by creating a sort of 'mental map' of the environment.</li>
		</ul>
	</div>
	
	<h3>Delivery</h3>
	The customer requires to receive the completion of the analysis (of the requirments and of the problem)  by <k>Friday 12 March</k>. 
	Hopefully, he/she expects to receive also (in the same document) some detail about the project.<br/>
	The name of the file (in pdf) should be:
	<pre>
		cognome_nome_ce.pdf
	</pre>

	 
<!-- ------------------------------------------------------------------------- -->
	<h2>Requirement analysis</h2>
	<div>
		The client requires the software system "<b>cautiousExplorer</b>". The interview has outlined the
		following meanings for the initial requirements:
		<ul>
			<li><ks>robot</ks> - a device that can move forward, backward and rotate, detecting when 
			it collides with obstacles. To execute the movements the robot receives commands through 
			the network, as described in <a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.virtualRobot2020/userDocs/VirtualRobot2021.html" target="lab"><em>VirtualRobot2021</em></a>.</li>
			<li><ks>closed environment</ks> - the space within which the robot exists and can move. This space
			has unknow dimensions and is delimited by walls, with which the robot collides. Moreover, it 
			contains an unknown number of obstacles, with which the robot collides.</li>
			<li><ks>den</ks> - the starting position of the robot. This is the space from which the robot begins
			to move to explore the environment and to which the robot returns whenever it encounters an 
			obstacle. This place must be editable only before the execution and has to be located near a wall.
			<!--otherwise the application won't work properly.--></li>
			<li><ks>organized way</ks> - means that the robot doesn't move in a random way, but it follows
			a pattern, so that it doesn't collide with the same obstacle more than once.</li>
			<li><ks>obstacles</ks> - fixed objects within the environment, that prevent the robot from passing 
			through them. Walls are obstacles too and the robot cannot tell the difference between the two.</li>
			<li><ks>cautious</ks> - the robot is 'cautios' because as soon as it collides with an obstacle, 
			which could involve a dangerous situations, it returns immediately to its den. It does not make 
			further	actions before doing so.</li>
			<li><ks>mental map</ks> - something the robot needs to remember the area it has explored (in 
			particular the position of the obstacles), so it does not collide with the same obstacles 
			and chooses a new path. The map can also be useful to recognize the best path if there are more 
			than once.</li> 
			<!-- we don't specify the meaning of "should remember" because we already described exhaustively
			what the client meant with "mental map" -->
			<li><ks>Optionally</ks> - it means that the referred feature (the sonar detection) can be enabled 
			and disabled at	will<!-- (maybe with a checkbox) -->.</li>
			<li><ks>sonar</ks> - a device located inside the environment or along its boundary, which can
			detect the robot within a certain range of action. The system can collect data from the software
			as described in <a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.virtualRobot2020/userDocs/VirtualRobot2021.html" target="lab"><em>VirtualRobot2021</em></a>.</li>
		</ul>
		About actions:
		<ul>
			<li><ks>lives</ks> - the robot exists, can move and perform all its exploring actions (the robot 
			does all of this inside the closed environment, it cannot leave or get out of its perimeter).</li>
			<li><ks>detect</ks> - know that the robot has passed through the range of action of the device
			(e.g. sonar).</li>
		</ul>	
		
		<h3 id="userStory1">Main user story</h3>
		<table style="width: 98%">
			<tr>
				<td style="width: 60%; padding: 10px">As a user I set the robot to start from the <ks>den</ks>.
				which is located near a wall. Then I enable the system <ks>cautiousExplorer</ks> that starts 
				sending commands to the robot through the network.<br/>
				The system collects informations about the robot actions, which are sent back to the system. 
				Then the system uses them to decide where to move the robot next. If the robot hits an 
				obstacle, it immediately returns back to the den. While the robot moves, the system 
				incrementally updates the mental map by adding the position of the obstacle found.<br/>
				When the system executions ends, I expect that the robot has successfully explored the whole
				environment.				
				<!-- every reachable spot inside the environment, finding the position of every obstacle inside of it.--></td>
				<td style="width: 40%; text-align: center"><img src="./img/cautiousExplorerUserStory1.png" alt="UserStoryIMG" width="90%"></td>
			</tr>
		</table>
		<h3 id="userStory2">Second user story (with presence detection option enabled)</h3>
		<table style="width: 98%">
			<tr>
				<td style="width: 60%; padding: 10px">As a user I set the robot to start from the <ks>den</ks>.
				which is located near a wall. Then I set the presence detection option to be ON and enable 
				the system <ks>cautiousExplorer</ks> that starts sending commands to the robot through the network.<br/>
				The system execution is the same of the main user story but, in this case, the robot returns
				immediately to the den even if a device (e.g. a sonar) detects its presence. If that happens, the system
				still updates the mental map, as the range of action of the sonar is perceived as "dangerous",
				so it is an obstacle too.
				<td style="width: 20%; text-align: center"><img src="./img/cautiousExplorerUserStory2 (1).png" alt="UserStoryIMG" width="90%">1) exploring phase</td>
				<td style="width: 20%; text-align: center"><img src="./img/cautiousExplorerUserStory2 (2).png" alt="UserStoryIMG" width="90%">2) return phase</td>
			</tr>
		</table>
		
		<h4>Informal first set of functional test plans</h4>
		<div>
			The TestPlan must verify that the robot, after a collision with an obstacle (or after the
			detection of its presence by a device, in case of the second user story), returns to the den, 
			as shown in the figure of the main user story. Moreover, after this, it must check that the robot actually 
			choose a different path so it doesn't hit the same obstacle again. This way the robot can 
			effectively explore the whole environment.<br/>
			In other words, the TestPlan purpose is to check that the map the system generates is the one
			that we would expect, by knowing the position of the obstacles (and the detection devices).
		</div>
	</div>
<!-- ------------------------------------------------------------------------- -->
	<h2>Problem analysis</h2>
	<div>
		<h3>Relevant aspects</h3>
		<div>
			As stated in <a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.virtualRobot2020/userDocs/VirtualRobot2021.html" target="lab"><em>VirtualRobot2021</em></a>,
			the robot can communicate with the system in two different ways:
			<ol>
				<li><ks>HTTP POST</ks> - the system sends a POST request message on the port <b>8090</b> and receive
				a response from the robot.</li>
				<li><ks>websocket</ks> - the system sends asynchronous message through the socket associated
				with the port <b>8091</b>, and the robot responds sending back informations.</li>
			</ol>
			For both of the communication protocols there are plenty of libraries in the most used
			programming languages, which includes Java and Node.<br/>
			Given that the system, if the option is enabled, could receive information from a device independent
			from the robot (e.g. sonar), the communication based on HTTP POST is not appropriate, since the HTTP
			protocol is based on a request/response model. As a matter of fact, the detection device can send data
			without a request. As a consequence, to use HTTP we would need to make a polling algorithm, which 
			generates overhead.<br/>
			Therefore, the best solution is to use the communication based on websocket.
			<br/>
			<br/>
			To make the system more modular and flexible, the designer could make reference to proper
			design principle and pattern, in particular:
			<a href="https://en.wikipedia.org/wiki/Single-responsibility_principle"><ks>Single Responsibility Principle</ks></a>
			on the whole system, <a href="https://en.wikipedia.org/wiki/Strategy_pattern"><ks>Strategy Pattern</ks></a>
			to implement the exploring algorithm and <a href="https://en.wikipedia.org/wiki/Observer_pattern"><ks>Observer Pattern</ks></a>
			to implement the asynchronous notify of the presence detection mechanism.
		</div>
		
		<h3>Main problems</h3>
		<ul>
			<li><ks>Explore algorithm</ks> - This is the main problem we have to solve to meet the
			requirements. Since the system incrementally builds the mental map, the best solution is to take
			advantage of this and move the robot according to the type of box near it. Basically we will have
			3 types of box: "<b>explored free</b>", "<b>explored obstacle</b>", "<b>not explored</b>". Given 
			that we set the following rules: the robot won't go toward the boxes marked as "explred obstacle";
			if the robot is near a "not explored" box and a "explored free" box, it will prefer the not
			explored one, since it represent a new exploring path.</li>
			<li><ks>Map representation</ks> - One of the main problems is the representation of the mental map. The 
			best way to build it is to use an approximated grid to divide the environment. Each box must be 
			the same size as the robot, that represent a <ks>robot unit</ks>.
			If the robot hits an obstacle, the box that contains it is marked entirely as an obstacle.</li>
			<li><ks>Robot language</ks> - with a map divided as described before, now the robot needs to 
			know a specific communication language. In particular, its movements will be based on the robot 
			unit (with fixed durations to match	the robot length). To acheive that, we can reuse the 
			<ks>aril</ks> language and the support implemented in 
			<a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.boundaryWalk/userDocs/BoundaryWalk.html#aril"><em>boundaryWalk</em></a>.</li>
			<li><ks>Map building</ks> - the map will be build incrementally using an algorithm or component
			given by the software house.</li>
			<li><ks>Return to den</ks> - when the robot hits an obstacle (or is detected by a device), it 
			returns to the den. To do this, it follows the same path it has traveled since he moved out 
			from the den, because it definitely has no obstacles along the way. Before returning back, the 
			robot turns itself, then retraces the path in reverse, as it is "running away from the danger"
			(which are the obstacles and detection devices).</li>
		</ul>
		
		<h3>Logical architecture</h3>
		<table style="width: 98%">
			<tr>
				<td>
				</td>
				<td style="width: 60%; text-align: center">Legend:<img src="./img/Legenda.png" alt="Legend" width="95%"></td>
			</tr>
			<tr>
				<td style="width: 60%; padding: 10px;">
					The system we must design has two software macro-components:
					<ol>
						<li>the <a href="https://htmlpreview.github.io/?https://github.com/anatali/issLab2021/blob/master/it.unibo.virtualRobot2020/userDocs/VirtualRobot2021.html" target="lab"><ks>VirtualRobot</ks></a>, given by the customer.</li>
						<li>the <ks>cautiousExplorer</ks> application that we have to write, which interacts 
						with the robot using asynchronous messages. This application will possibly be made using
						different classes or sub-components</li>
					</ol>
				</td>
				<td style="text-align: center"><img src="./img/cautiousExplorerLogicalArchitecture.png" alt="Logical Architecture" width="95%"/></td>
			</tr>
		</table>
	</div>

<!-- ------------------------------------------------------------------------- -->
	<h2>Test plans</h2> 
	<div>
		The test purpose is to check that:
		<ol>
			<li>the robot returns to the den using the same path but done in reverse (not backwards).</li>
			<li>the mental map built is the one we would expect.</li>
			<li>after returning to the den the robot chooses a new path.</li>
		</ol>
		<h4>1. Returning path</h4>
		If the exploring path uses the following sequence of commands:<br/>
		<b>forward, left, forward, forward</b>.<br/>
		then the returning sequence must be:<br/>
		<b>left, left, forward, forward, right, forward.</b><br/>
		The first 2 "left" means that the robot rotates of 180 degrees.<br/>
		To get this we must:
		<ol>
			<li>create a new empty command sequence.</li>
			<li>add 2 rotation in the same direction (e.g. left) at the beginning.</li>
			<li>add the exploring sequence in reverse (from the end to the beginning).</li>
			<li>invert the rotation from left to right and from right to left.</li>
		</ol>
		
		Given the way we must calculate the returning sequence, we can test if the robot follows the path.
		In JUnit pseudocode:
<pre>
private robot;
private expectedReturnSequence;

@Before
public void init()
{
	this.robot.create();
	this.robot.setDen();
	this.expectedReturnSequence = "forward, forward, right, forward";
}

@Test
public void checkReturnSequence()
{
	this.robot.sendCmd(forward);
	this.robot.sendCmd(left);
	this.robot.sendCmd(forward);
	this.robot.sendCmd(forward);
	// obstacle hit (the robot reactively returns to the den)
	assertTrue(compareSequence(this.robot.getLastSequence(), this.expectedReturnSequence));
}
</pre>

		<h4>2. Mental map</h4>
		We must check that the obstacles in the generated mental map are in the same position as the ones we
		know they are. To do this we move the robot with a predefined sequence of commands, to collide with
		an obstacle, then compare the generated map with the one with obstacles in the right position.
		In JUnit pseudocode:
<pre>
private robot;
private expectedMentalMap;

@Before
public void init()
{
	this.robot.create();
	this.robot.setDen();
	this.expectedMentalMap = "..."; // obstacle in the right position
}

@Test
public void checkMentalMap()
{
	this.robot.sendCmd(forward);
	this.robot.sendCmd(left);
	this.robot.sendCmd(forward);
	this.robot.sendCmd(forward);
	// obstacle hit (the robot reactively returns to the den)
	assertTrue(compareMapObstacles(this.robot.getMap(), this.expectedMentalMap));
}
</pre>
		
		<h4>3. Different exploring path</h4>
		We must check that the robot, after it return to den, will choose a path that is different from the
		one that took it to hitting the obstacle. Otherwise, the robot will get into a loop without
		exploring any other areas. <br/>
		Given our exploring algorithm, we set the test so the robot start from a den that is near an 
		obstacle. Then we make the robot go straight forward to hit the obstacle and make it return to the
		den. After this we activate the exploring algorithm, to check if the new path is different and we
		compare the move sequences.
		In JUnit pseudocode:
<pre>
private robot;
private sequence;

@Before
public void init()
{
	this.robot.create();
	this.robot.setDen();
	this.sequence = "forward, forward";
}

@Test
public void checkExploringAlgorithm()
{
	while( true )
	{
		this.robot.sendCmd(forward);
		if(this.robot.collision) // obstacle hit
		{
			this.sequence = this.robot.getLastSequence(); // sequence from den
		}
	}	
	// the robot returns to the den
		
	this.robot.explore(); // exploring algorithm activated
	wait();
	
	// compares the sequence from last return to den with the new sequence
	assertTrue(!compareMapObstacles(this.robot.getLastSequence(), this.sequence));
}
</pre>
	</div>

<!-- ------------------------------------------------------------------------- -->
	<h2 id="project">Project</h2>
	<table style="width: 98%">
	<tr>
		<td style="padding: 10px">
			<h3>Nature of the application</h3>
			Since the system uses the asynchronous communication, implemented through the pattern observer, there 
			will be at least 2 threads: the first is the main thread, which task is to run the execution flow.
			The second one is the one that handles the asynchronous messages of the detection mechanism.
		</td>
		<td style="width: 30%; text-align: center"><img src="./img/ComponentNature.png" alt="AppNature" width="95%"><br/>TODO</td>
		
	</tr>
	<tr>
		<td style="padding: 10px">
			<h3>Project architecture</h3>
		</td>
		<td style="width: 30%; text-align: center"><img src="./img/Architettura di progetto.png" alt="ProjectArchitecture" width="95%"><br/>TODO</td>
		
	</tr>
	<tr>
		<td style="width: 50%; padding: 10px">
			<h3>Exploring algorithm</h3>
			The exploration algorithm can be summarized through the flow chart shown on the right: the
			exploration goes on "in waves" (or rings) of different levels, starting from the den which is 0, increasing
			by one for each level around it.
			<br/>
			The exploring algorithm will be injected into the system through the pattern strategy. This way
			if the application will evolve or change in the future, there will be the possibility to 
			substitute the algorithm with another one more suitable to new requirements.
		</td>
		<td style="width: 30%; text-align: center"><img src="./img/DiagrammaDiFlusso.png" alt="Legend" width="95%"></td>
	</tr>
	</table>
	<br/>
	Execution example:
	<table style="width: 98%">
	<tr>
		<td style="width: 25%; text-align: center"><img src="./img/GrigliaMappa1.png" alt="Legend" width="95%">(1) </td>
		<td style="width: 25%; text-align: center"><img src="./img/GrigliaMappa2.png" alt="Legend" width="95%">(2) </td>
		<td style="width: 25%; text-align: center"><img src="./img/GrigliaMappa3.png" alt="Legend" width="95%">(3) </td>
		<td style="width: 25%; text-align: center"><img src="./img/GrigliaMappa4.png" alt="Legend" width="95%">(4) </td>
		
	</tr>
	</table>
	
<!-- ------------------------------------------------------------------------- -->
	<h2>Testing</h2>
	<div>
		
	</div>
 
<!-- ------------------------------------------------------------------------- -->
	<h2>Deployment</h2>
	<div>
		
	</div>

<!-- ------------------------------------------------------------------------- -->
	<h2>Maintenance</h2>
	<div>
		
	</div>
 
<!-- USEFUL
<table style="width:100%" border="1">
<tr>
<td style="width:50%">
</td>
<td></td>
</tr>
</table>
-->


<!-- ========================================================================= -->

	<table class="separator" style="width:100%" border="1">
		<tr>
			<td style="width:50%"/>
			<td/>
		</tr>
	</table>
				
	<br/>
</div>

<div id="footer" style="background-color:rgba(86, 56, 253, 0.9); width:60%; text-align:left;color:white">
	<p style="float: left; width: 72%; padding: 10px">
		By <b>Michele Righi</b><br/><br/>
		email: michele.righi5@studio.unibo.it<br/>
		github: <a id="github" href="https://github.com/mikyll">mikyll</a><br/>
		ISS repo: <a id="github" href="https://github.com/mikyll/righimichele">mikyll/righimichele</a><br/>
		<!--cautiousExplorer repo: <a id="github" href="https://github.com/mikyll/righimichele/it.unibo.cautiousExplorer">mikyll/righimichele/it.unibo.cautiousExplorer</a><br/>-->
	</p>
	<center><img src="./img/Michele.png" alt="Michele Righi" width="120px" height="159px"/></center>
</div>

</body></html>